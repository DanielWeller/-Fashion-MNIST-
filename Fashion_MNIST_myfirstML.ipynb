{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST_myfirstML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPh-P0t8FS5v",
        "colab_type": "code",
        "outputId": "b5430a57-fc5c-42ba-92d7-42a57aacc422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFEKt00GFLjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import essentials\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95e0LXzIGSgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6CpBX-VGYNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a dictionary for easy access to object classes\n",
        "objects = {0: 'T-shirt/top',\n",
        "           1: 'Trouser',\n",
        "           2: 'Pullover',\n",
        "           3: 'Dress',\n",
        "           4: 'Coat',\n",
        "           5: 'Sandal',\n",
        "           6: 'Shirt',\n",
        "           7: 'Sneaker',\n",
        "           8: 'Bag',\n",
        "           9: 'Ankle boot'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg6uIDLVGmgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS5kW1g1Gz83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_classes = 10\n",
        "train_vec_labels = keras.utils.to_categorical(train_labels, total_classes)\n",
        "test_vec_labels = keras.utils.to_categorical(test_labels, total_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxYesjgWHK9d",
        "colab_type": "code",
        "outputId": "f4fe55f3-bba1-4b30-8950-f775d0ca3787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "model_relu = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_linear = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='linear'),\n",
        "    keras.layers.Dense(10, activation='linear')\n",
        "])\n",
        "\n",
        "model_sigmoid = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='sigmoid'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_tanh = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='tanh'),\n",
        "    keras.layers.Dense(10, activation='tanh')\n",
        "])\n",
        "\n",
        "models = [model_relu, model_linear,\n",
        "          model_sigmoid,model_tanh]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4TVodpSHVY-",
        "colab_type": "code",
        "outputId": "63cf2603-3c0c-44ed-f8a9-32df92c61b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[\n",
        "  model.compile(\n",
        "      optimizer='sgd',\n",
        "      loss='mean_squared_error',\n",
        "      metrics=['accuracy']\n",
        "  ) for model in models\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcjebf8HHW_X",
        "colab_type": "code",
        "outputId": "69022ff7-b16f-43ab-a53e-163c0edbbb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs=15\n",
        "[\n",
        " model.fit(\n",
        "    train_images,\n",
        "    train_vec_labels,\n",
        "    epochs=epochs,\n",
        "    verbose=True\n",
        "  ) for model in models\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0966 - acc: 0.3833\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0707 - acc: 0.5767\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0595 - acc: 0.6436\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0529 - acc: 0.6823\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0487 - acc: 0.7054\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0458 - acc: 0.7229\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0436 - acc: 0.7382\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0418 - acc: 0.7478\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0403 - acc: 0.7577\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0390 - acc: 0.7653\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0380 - acc: 0.7719\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0370 - acc: 0.7777\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0362 - acc: 0.7828\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0354 - acc: 0.7867\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0348 - acc: 0.7902\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0845 - acc: 0.6296\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0558 - acc: 0.7537\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.0492 - acc: 0.7792\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0458 - acc: 0.7905\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0438 - acc: 0.7974\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0424 - acc: 0.8024\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0413 - acc: 0.8060\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0406 - acc: 0.8080\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0399 - acc: 0.8103\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0395 - acc: 0.8120\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0390 - acc: 0.8134\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0387 - acc: 0.8151\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0384 - acc: 0.8151\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.0381 - acc: 0.8162\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0379 - acc: 0.8169\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0989 - acc: 0.2352\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0862 - acc: 0.3650\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0836 - acc: 0.4326\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0808 - acc: 0.4698\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0778 - acc: 0.5024\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0750 - acc: 0.5302\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0723 - acc: 0.5575\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0699 - acc: 0.5844\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0677 - acc: 0.6025\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0657 - acc: 0.6256\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0639 - acc: 0.6391\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0623 - acc: 0.6527\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0608 - acc: 0.6684\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0594 - acc: 0.6779\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0581 - acc: 0.6861\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0740 - acc: 0.6354\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0514 - acc: 0.7650\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0458 - acc: 0.7891\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0428 - acc: 0.8000\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0408 - acc: 0.8060\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0393 - acc: 0.8109\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0381 - acc: 0.8144\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0372 - acc: 0.8166\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0363 - acc: 0.8195\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0357 - acc: 0.8215\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0351 - acc: 0.8226\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0345 - acc: 0.8243\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0341 - acc: 0.8256\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0337 - acc: 0.8271\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0333 - acc: 0.8280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.History at 0x7fd30ea98be0>,\n",
              " <tensorflow.python.keras.callbacks.History at 0x7fd30eab6588>,\n",
              " <tensorflow.python.keras.callbacks.History at 0x7fd34a2942b0>,\n",
              " <tensorflow.python.keras.callbacks.History at 0x7fd30879acc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj6Jsia1IWcG",
        "colab_type": "code",
        "outputId": "b0e7f78c-06e0-4e54-de40-05c2c0faacca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "!pip install --upgrade deeplearning2020\n",
        "from deeplearning2020 import Submission\n",
        "Submission('0697a902146c82a4ebe95c579234f97c', '2', model_tanh).submit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: deeplearning2020 in /usr/local/lib/python3.6/dist-packages (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: kerasltisubmission>=0.4.5 in /usr/local/lib/python3.6/dist-packages (from deeplearning2020) (0.4.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from kerasltisubmission>=0.4.5->deeplearning2020) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: progressbar2 in /usr/local/lib/python3.6/dist-packages (from kerasltisubmission>=0.4.5->deeplearning2020) (3.38.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kerasltisubmission>=0.4.5->deeplearning2020) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from progressbar2->kerasltisubmission>=0.4.5->deeplearning2020) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->kerasltisubmission>=0.4.5->deeplearning2020) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kerasltisubmission>=0.4.5->deeplearning2020) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->kerasltisubmission>=0.4.5->deeplearning2020) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kerasltisubmission>=0.4.5->deeplearning2020) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->kerasltisubmission>=0.4.5->deeplearning2020) (1.24.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Assignment 2 erfolgreich abgegeben!\n",
            "Dein Model hat eine Accuracy von 83.0% auf unseren Validierungsdaten.\n",
            "Du erhältst 100.0% der Punkte auf dieses Assignment.\n",
            "Falls du bereits eine Abgabe mit höherer Bewertung abgegeben hast, wird automatisch das bessere Ergebnis gewählt.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}